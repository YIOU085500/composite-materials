import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from xgboost import XGBRegressor
from sklearn.model_selection import RepeatedKFold
from sklearn.metrics import r2_score, mean_absolute_error
from sklearn.preprocessing import MinMaxScaler
import os
import joblib
from io import BytesIO

# ==============================================================================
# 1. ä»æ‚¨æä¾›çš„è„šæœ¬ä¸­æ•´åˆçš„æ ¸å¿ƒå‡½æ•° (ç¨ä½œä¿®æ”¹ä»¥é€‚åº”Streamlit)
# ==============================================================================

# --- æ•°æ®é¢„å¤„ç†å‡½æ•° ---
def clean_dataframe(df):
    """æ¸…ç†DataFrameä¸­å¯èƒ½å­˜åœ¨çš„ç©ºåˆ—æˆ–æ ¼å¼é—®é¢˜ã€‚"""
    df.dropna(axis=1, how='all', inplace=True)
    unnamed_cols = [col for col in df.columns if 'Unnamed' in col]
    if unnamed_cols:
        df.drop(columns=unnamed_cols, inplace=True)
    return df

def calculate_weights_3D(df, norm_cols, bins_per_dim=4):
    """æ ¹æ®ä¸‰ä¸ªå½’ä¸€åŒ–åçš„ç»´åº¦ï¼Œé€šè¿‡3Dåˆ†ç®±æ¥è®¡ç®—æ ·æœ¬æƒé‡ã€‚"""
    temp_df = df.copy()
    binned_cols = []
    for i, col in enumerate(norm_cols):
        binned_col_name = f'bin_{i}'
        temp_df[binned_col_name] = pd.cut(temp_df[col], bins=bins_per_dim, labels=False, include_lowest=True)
        binned_cols.append(binned_col_name)
    
    group_sizes = temp_df.groupby(binned_cols)[binned_cols[0]].transform('size')
    weights = 1.0 / group_sizes
    return weights

def process_data_for_training(df):
    """
    åŠ è½½DataFrameï¼Œè¿›è¡Œå½’ä¸€åŒ–å’Œæƒé‡åˆ†é…ï¼Œè¿”å›å¤„ç†åçš„DataFrameå’Œscalerã€‚
    """
    df = clean_dataframe(df.copy())
    
    feature_cols = ['è€åŒ–æ¸©åº¦', 'è€åŒ–æ¹¿åº¦', 'è€åŒ–æ—¶é—´']
    if not all(col in df.columns for col in feature_cols):
        st.error(f"é”™è¯¯ï¼šä¸Šä¼ çš„æ–‡ä»¶ä¸­ç¼ºå°‘å¿…è¦çš„åˆ—ã€‚éœ€è¦ {feature_cols}ï¼Œä½†åªæ‰¾åˆ°äº† {list(df.columns)}ã€‚")
        return None, None
        
    scaler = MinMaxScaler()
    normalized_features = scaler.fit_transform(df[feature_cols])
    normalized_cols = [f'{col}_normalized' for col in feature_cols]
    df[normalized_cols] = normalized_features

    sample_weights = calculate_weights_3D(df, norm_cols=normalized_cols, bins_per_dim=4)
    df['sample_weight'] = sample_weights
    
    return df, scaler

# --- æœºå™¨å­¦ä¹ ä¸å¯è§†åŒ–å‡½æ•° ---
def train_and_visualize_model(df, features, target, title):
    """
    æ‰§è¡Œäº¤å‰éªŒè¯ï¼Œè®­ç»ƒæœ€ç»ˆæ¨¡å‹ï¼Œå¹¶ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ã€‚
    è¿”å›: model, scaler, figure, metrics
    """
    if df is None or df.empty or len(df) < 20:
        st.warning(f"æ•°æ®é‡è¿‡å°‘ ({len(df)}ä¸ªæ ·æœ¬)ï¼Œæ— æ³•è¿›è¡Œå¯é çš„è®­ç»ƒï¼Œè¯·ä¸Šä¼ æ›´å¤šæ•°æ®ã€‚")
        return None, None, None

    X = df[features]
    y = df[target]
    
    # æ‰§è¡Œé‡å¤KæŠ˜äº¤å‰éªŒè¯
    rkf = RepeatedKFold(n_splits=5, n_repeats=5, random_state=42)
    r2_scores, mae_scores = [], []
    model_params = {
        'objective': 'reg:squarederror', 'n_estimators': 200, 'max_depth': 5,
        'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.8,
        'random_state': 42, 'n_jobs': -1
    }

    for train_index, val_index in rkf.split(X, y):
        X_train, X_val = X.iloc[train_index], X.iloc[val_index]
        y_train, y_val = y.iloc[train_index], y.iloc[val_index]
        weights_train = df['sample_weight'].iloc[train_index]

        model_cv = XGBRegressor(**model_params)
        model_cv.fit(X_train, y_train, sample_weight=weights_train)
        y_pred = model_cv.predict(X_val)
        
        r2_scores.append(r2_score(y_val, y_pred))
        mae_scores.append(mean_absolute_error(y_val, y_pred))
    
    avg_r2, std_r2 = np.mean(r2_scores), np.std(r2_scores)
    avg_mae, std_mae = np.mean(mae_scores), np.std(mae_scores)
    metrics = {'r2': avg_r2, 'r2_std': std_r2, 'mae': avg_mae, 'mae_std': std_mae}

    # è®­ç»ƒæœ€ç»ˆæ¨¡å‹
    final_model = XGBRegressor(**model_params)
    final_model.fit(X, y, sample_weight=df['sample_weight'])

    # ç”Ÿæˆ3Då“åº”é¢å¯è§†åŒ–
    fig = go.Figure()
    weld_statuses = {0: {'name': 'æ— ç†”æ¥ç—•', 'color': 'blue'}, 1: {'name': 'æœ‰ç†”æ¥ç—•', 'color': 'red'}}
    grid_resolution = 30
    
    for status_code, props in weld_statuses.items():
        subset_df = df[df['æœ‰æ— ç†”æ¥ç—•(0/1)'] == status_code]
        if not subset_df.empty:
            fig.add_trace(go.Scatter3d(
                x=subset_df[features[0]], y=subset_df[features[1]], z=subset_df[target],
                mode='markers',
                marker=dict(size=5, color=props['color'], symbol='circle' if status_code == 0 else 'diamond', opacity=0.7),
                name=f'åŸå§‹æ•°æ® ({props["name"]})'
            ))

        unique_humidity_levels = np.linspace(X[features[2]].min(), X[features[2]].max(), 3) # å¯è§†åŒ–3ä¸ªæ¹¿åº¦æ°´å¹³
        for humidity_level in unique_humidity_levels:
            temp_range = np.linspace(X[features[0]].min(), X[features[0]].max(), grid_resolution)
            time_range = np.linspace(X[features[1]].min(), X[features[1]].max(), grid_resolution)
            grid_temp, grid_time = np.meshgrid(temp_range, time_range)
            grid_humidity = np.full(grid_temp.shape, humidity_level)
            
            predict_df = pd.DataFrame({
                features[0]: grid_temp.flatten(),
                features[1]: grid_time.flatten(),
                features[2]: grid_humidity.flatten(),
                features[3]: status_code
            })
            
            predicted_strength = final_model.predict(predict_df)
            grid_strength = predicted_strength.reshape(grid_temp.shape)
            
            colorscale = 'Blues' if status_code == 0 else 'Reds'
            fig.add_trace(go.Surface(
                x=temp_range, y=time_range, z=grid_strength,
                opacity=0.7, colorscale=colorscale, showscale=False,
                name=f'æ¨¡å‹å“åº”é¢ ({props["name"]}, æ¹¿åº¦={humidity_level:.2f})'
            ))

    fig.update_layout(
        title=f'<b>{title} å¼ºåº¦é¢„æµ‹æ¨¡å‹</b><br>äº¤å‰éªŒè¯ RÂ²: {avg_r2:.3f} Â± {std_r2:.3f}',
        scene=dict(
            xaxis_title=f"{features[0].replace('_normalized', '')}",
            yaxis_title=f"{features[1].replace('_normalized', '')}",
            zaxis_title=target
        ),
        legend=dict(x=0.01, y=0.99),
        margin=dict(l=0, r=0, b=0, t=60)
    )
    
    return final_model, fig, metrics

# ==============================================================================
# 2. Streamlit ç½‘é¡µåº”ç”¨ç•Œé¢ä¸é€»è¾‘
# ==============================================================================

st.set_page_config(page_title="ææ–™å¼ºåº¦é¢„æµ‹ä¸åˆ†æå¹³å°", layout="wide")

st.title("ææ–™å¼ºåº¦æ™ºèƒ½é¢„æµ‹ä¸åˆ†æå¹³å° ğŸ“ˆ")

# --- ä¾§è¾¹æ  ---
st.sidebar.header("âš™ï¸ æ“ä½œé¢æ¿")
app_mode = st.sidebar.selectbox("é€‰æ‹©æ“ä½œæ¨¡å¼", ["è®­ç»ƒæ–°æ¨¡å‹", "åŠ è½½æ¨¡å‹å¹¶é¢„æµ‹"])
model_type = st.sidebar.radio("é€‰æ‹©æ¨¡å‹ç±»å‹", ('æ‹‰ä¼¸å¼ºåº¦', 'å¼¯æ›²å¼ºåº¦'), key="model_type_selection")

# --- æ ¹æ®æ¨¡å¼é€‰æ‹©ï¼Œæ¸²æŸ“ä¸åŒé¡µé¢ ---

if app_mode == "è®­ç»ƒæ–°æ¨¡å‹":
    st.header("æ¨¡å¼ä¸€: è®­ç»ƒæ–°çš„é¢„æµ‹æ¨¡å‹")

    # 1. ä¸Šä¼ æ–‡ä»¶
    st.subheader("æ­¥éª¤ 1: ä¸Šä¼ æ‚¨çš„æ•°æ®æ–‡ä»¶")
    
    with st.expander("ç‚¹æ­¤æŸ¥çœ‹æ•°æ®æ ¼å¼è¦æ±‚", expanded=False):
        st.info(
            """
            è¯·ä¸Šä¼ ä¸€ä¸ªCSVæ–‡ä»¶ï¼Œç¡®ä¿åŒ…å«ä»¥ä¸‹**å¿…éœ€**çš„åˆ—ï¼š
            - `è€åŒ–æ¸©åº¦`: æ•°å€¼å‹ (ä¾‹å¦‚: 80, 90.5)
            - `è€åŒ–æ¹¿åº¦`: æ•°å€¼å‹ (ä¾‹å¦‚: 75, 85)
            - `è€åŒ–æ—¶é—´`: æ•°å€¼å‹ (ä¾‹å¦‚: 24, 48)
            - `æœ‰æ— ç†”æ¥ç—•(0/1)`: æ•°å€¼å‹ (0ä»£è¡¨æ— ï¼Œ1ä»£è¡¨æœ‰)
            - `æ‹‰ä¼¸å¼ºåº¦` æˆ– `å¼¯æ›²å¼ºåº¦`: æ•°å€¼å‹ï¼Œä½œä¸ºé¢„æµ‹ç›®æ ‡ã€‚
            
            **æ³¨æ„**: æ–‡ä»¶ä¸­åªéœ€åŒ…å«å¯¹åº”æ¨¡å‹ç±»å‹çš„å¼ºåº¦åˆ—å³å¯ï¼ˆä¾‹å¦‚ï¼Œè®­ç»ƒæ‹‰ä¼¸å¼ºåº¦æ¨¡å‹æ—¶ï¼Œæ–‡ä»¶ä¸­å¿…é¡»æœ‰`æ‹‰ä¼¸å¼ºåº¦`åˆ—ï¼‰ã€‚
            """
        )
        st.dataframe(pd.DataFrame({
            'è€åŒ–æ¸©åº¦': [85, 90], 'è€åŒ–æ¹¿åº¦': [75, 80], 'è€åŒ–æ—¶é—´': [24, 48],
            'æœ‰æ— ç†”æ¥ç—•(0/1)': [0, 1], model_type: [120.5, 98.2]
        }))

    uploaded_file = st.file_uploader(f"è¯·ä¸Šä¼ ç”¨äºè®­ç»ƒ **{model_type}** æ¨¡å‹çš„æ•°æ®", type="csv")

    # 2. è®­ç»ƒæŒ‰é’®å’Œæ‰§è¡Œ
    if uploaded_file is not None:
        if st.button(f"ğŸš€ å¼€å§‹è®­ç»ƒ {model_type} æ¨¡å‹", use_container_width=True):
            with st.spinner("æ­£åœ¨å¤„ç†æ•°æ®å¹¶è®­ç»ƒæ¨¡å‹ï¼Œè¯·ç¨å€™..."):
                try:
                    df = pd.read_csv(uploaded_file)
                    
                    # æ£€æŸ¥ç›®æ ‡åˆ—æ˜¯å¦å­˜åœ¨
                    if model_type not in df.columns:
                        st.error(f"ä¸Šä¼ çš„æ–‡ä»¶ä¸­ç¼ºå°‘ç›®æ ‡åˆ— '{model_type}'ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹ã€‚")
                    else:
                        # æ•°æ®é¢„å¤„ç†
                        processed_df, scaler = process_data_for_training(df)
                        
                        if processed_df is not None:
                            # å®šä¹‰ç‰¹å¾å’Œç›®æ ‡
                            features = ['è€åŒ–æ¸©åº¦_normalized', 'è€åŒ–æ—¶é—´_normalized', 'è€åŒ–æ¹¿åº¦_normalized', 'æœ‰æ— ç†”æ¥ç—•(0/1)']
                            target = model_type
                            
                            # è®­ç»ƒå¹¶è·å–ç»“æœ
                            model, fig, metrics = train_and_visualize_model(processed_df, features, target, model_type)
                            
                            if model:
                                st.success("æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
                                
                                # ä¿å­˜ç»“æœåˆ° session_state ä»¥ä¾¿åç»­ä½¿ç”¨
                                st.session_state['trained_model'] = model
                                st.session_state['scaler'] = scaler
                                st.session_state['figure'] = fig
                                st.session_state['metrics'] = metrics
                                st.session_state['model_type'] = model_type
                                st.session_state['features'] = features

                except Exception as e:
                    st.error(f"å¤„ç†æ–‡ä»¶æˆ–è®­ç»ƒæ¨¡å‹æ—¶å‘ç”Ÿé”™è¯¯: {e}")

    # 3. å±•ç¤ºè®­ç»ƒç»“æœ
    if 'figure' in st.session_state and st.session_state['model_type'] == model_type:
        st.header("ğŸ“Š è®­ç»ƒç»“æœä¸åˆ†æ")
        
        # å¸ƒå±€
        col1, col2 = st.columns([2.5, 1.5])

        with col1:
            st.subheader("ä¸‰ç»´å“åº”é¢ä¸æ•°æ®åˆ†å¸ƒ")
            st.plotly_chart(st.session_state['figure'], use_container_width=True)
            with st.expander("å›¾è¡¨è§£è¯»"):
                st.markdown(
                    """
                    è¿™ä¸ª3Då›¾è¡¨å±•ç¤ºäº†æ¨¡å‹å­¦ä¹ åˆ°çš„è§„å¾‹ï¼š
                    - **æ•£ç‚¹**: ä»£è¡¨æ‚¨çš„åŸå§‹æ•°æ®ç‚¹ã€‚è“è‰²è¡¨ç¤ºæ— ç†”æ¥ç—•æ ·æœ¬ï¼Œçº¢è‰²è¡¨ç¤ºæœ‰ç†”æ¥ç—•æ ·æœ¬ã€‚
                    - **å½©è‰²æ›²é¢**: è¿™æ˜¯æ¨¡å‹ç”Ÿæˆçš„â€œå“åº”é¢â€ï¼Œå®ƒé¢„æµ‹äº†åœ¨ä¸åŒ`è€åŒ–æ¸©åº¦`å’Œ`è€åŒ–æ—¶é—´`ç»„åˆä¸‹çš„ææ–™å¼ºåº¦ã€‚
                      - **è“è‰²æ›²é¢** å¯¹åº” **æ— ç†”æ¥ç—•** çš„æƒ…å†µã€‚
                      - **çº¢è‰²æ›²é¢** å¯¹åº” **æœ‰ç†”æ¥ç—•** çš„æƒ…å†µã€‚
                    - **äº¤äº’æ“ä½œ**: æ‚¨å¯ä»¥æ‹–åŠ¨å›¾è¡¨è¿›è¡Œæ—‹è½¬ï¼Œæ»šåŠ¨é¼ æ ‡æ»šè½®è¿›è¡Œç¼©æ”¾ï¼Œä»¥ä¾¿ä»ä¸åŒè§’åº¦è§‚å¯Ÿæ•°æ®å’Œæ¨¡å‹æ›²é¢ã€‚
                    - **åˆ†æ**: é€šè¿‡è§‚å¯Ÿæ›²é¢çš„é«˜ä½å’Œèµ°åŠ¿ï¼Œå¯ä»¥ç›´è§‚åœ°åˆ¤æ–­å‡ºå“ªäº›å·¥è‰ºå‚æ•°ç»„åˆèƒ½å¸¦æ¥æ›´é«˜çš„ææ–™å¼ºåº¦ã€‚
                    """
                )

        with col2:
            st.subheader("æ¨¡å‹æ€§èƒ½è¯„ä¼°")
            metrics = st.session_state['metrics']
            st.metric(label="RÂ² (å†³å®šç³»æ•°)", value=f"{metrics['r2']:.4f}", help="è¶Šæ¥è¿‘1è¶Šå¥½ï¼Œè¡¨ç¤ºæ¨¡å‹å¯¹æ•°æ®å˜å¼‚æ€§çš„è§£é‡Šèƒ½åŠ›è¶Šå¼ºã€‚")
            st.metric(label="MAE (å¹³å‡ç»å¯¹è¯¯å·®)", value=f"{metrics['mae']:.4f}", help=f"è¡¨ç¤ºé¢„æµ‹å€¼ä¸çœŸå®å€¼çš„å¹³å‡å·®å¼‚å¤§å°ã€‚æ­¤æ¨¡å‹çš„å¹³å‡é¢„æµ‹è¯¯å·®ä¸º {metrics['mae']:.4f}ã€‚")
            
            with st.expander("è¯„ä¼°æŒ‡æ ‡çš„æ„ä¹‰", expanded=True):
                 st.markdown(
                    f"""
                    #### **RÂ² (R-squared / å†³å®šç³»æ•°)**
                    - **æ˜¯ä»€ä¹ˆ?** RÂ²åˆ†æ•°è¡¡é‡çš„æ˜¯æ¨¡å‹å¯¹æ•°æ®å˜åŒ–çš„è§£é‡Šç¨‹åº¦ã€‚å®ƒçš„å–å€¼èŒƒå›´é€šå¸¸åœ¨0åˆ°1ä¹‹é—´ã€‚
                    - **å¦‚ä½•è§£è¯»?**
                        - **RÂ² = 1**: å®Œç¾æ¨¡å‹ï¼Œæ¨¡å‹è§£é‡Šäº†æ•°æ®ä¸­100%çš„å˜åŒ–ã€‚
                        - **RÂ² = {metrics['r2']:.2f}**: å½“å‰æ¨¡å‹å¯ä»¥è§£é‡Šçº¦ **{metrics['r2']*100:.1f}%** çš„æ•°æ®æ–¹å·®ã€‚è¿™æ˜¯ä¸€ä¸ªç›¸å½“ä¸é”™çš„æ€§èƒ½ï¼Œè¯´æ˜æ¨¡å‹å¾ˆå¥½åœ°æ•æ‰äº†å…³é”®å˜é‡ä¹‹é—´çš„å…³ç³»ã€‚
                        - **RÂ² = 0**: æ¨¡å‹æ€§èƒ½ç­‰åŒäºä¸€ä¸ªç®€å•çš„å¹³å‡å€¼é¢„æµ‹ï¼Œæ²¡æœ‰å­¦åˆ°ä»»ä½•æœ‰æ•ˆä¿¡æ¯ã€‚

                    #### **MAE (Mean Absolute Error / å¹³å‡ç»å¯¹è¯¯å·®)**
                    - **æ˜¯ä»€ä¹ˆ?** MAEè®¡ç®—çš„æ˜¯æ¯ä¸ªæ ·æœ¬çš„é¢„æµ‹å€¼ä¸çœŸå®å€¼ä¹‹å·®çš„ç»å¯¹å€¼çš„å¹³å‡æ•°ã€‚
                    - **å¦‚ä½•è§£è¯»?**
                        - å®ƒçš„å•ä½ä¸æ‚¨çš„ç›®æ ‡å€¼ï¼ˆ{model_type}ï¼‰ç›¸åŒã€‚
                        - **MAE = {metrics['mae']:.2f}**: æ„å‘³ç€æ¨¡å‹çš„é¢„æµ‹ç»“æœå¹³å‡ä¼šä¸çœŸå®å€¼ç›¸å·®çº¦ **{metrics['mae']:.2f}**ã€‚è¿™ä¸ªå€¼è¶Šå°ï¼Œä»£è¡¨æ¨¡å‹çš„é¢„æµ‹è¶Šç²¾å‡†ã€‚
                    """
                )
        
        # 4. ä¿å­˜æ¨¡å‹
        st.subheader("æ­¥éª¤ 2: ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹")
        st.info("æ‚¨å¯ä»¥å°†å½“å‰è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆåŒ…æ‹¬æ•°æ®å½’ä¸€åŒ–è§„åˆ™ï¼‰ä¿å­˜ä¸‹æ¥ï¼Œä»¥ä¾¿æœªæ¥ç›´æ¥åŠ è½½ä½¿ç”¨ã€‚")
        
        # å°†æ¨¡å‹å’Œscaleræ‰“åŒ…
        model_to_save = {
            'model': st.session_state['trained_model'],
            'scaler': st.session_state['scaler'],
            'model_type': st.session_state['model_type'],
            'features': st.session_state['features']
        }
        
        # ä½¿ç”¨BytesIOåœ¨å†…å­˜ä¸­åˆ›å»ºæ–‡ä»¶
        buffer = BytesIO()
        joblib.dump(model_to_save, buffer)
        buffer.seek(0)

        st.download_button(
            label=f"ğŸ“¥ ä¸‹è½½ {model_type} æ¨¡å‹æ–‡ä»¶ (.joblib)",
            data=buffer,
            file_name=f"{model_type}_model.joblib",
            mime="application/octet-stream",
            use_container_width=True
        )

# ==============================================================================
# "åŠ è½½æ¨¡å‹å¹¶é¢„æµ‹" é¡µé¢
# ==============================================================================
elif app_mode == "åŠ è½½æ¨¡å‹å¹¶é¢„æµ‹":
    st.header("æ¨¡å¼äºŒ: åŠ è½½å·²æœ‰æ¨¡å‹å¹¶è¿›è¡Œé¢„æµ‹")
    
    st.subheader("æ­¥éª¤ 1: ä¸Šä¼ æ‚¨çš„æ¨¡å‹æ–‡ä»¶")
    uploaded_model_file = st.file_uploader(
        "è¯·ä¸Šä¼ ä¹‹å‰ä¿å­˜çš„ .joblib æ¨¡å‹æ–‡ä»¶", 
        type="joblib"
    )

    if uploaded_model_file:
        try:
            # åŠ è½½æ¨¡å‹å’Œscaler
            model_data = joblib.load(uploaded_model_file)
            model = model_data['model']
            scaler = model_data['scaler']
            loaded_model_type = model_data['model_type']
            features = model_data['features']
            
            st.success(f"æˆåŠŸåŠ è½½ **{loaded_model_type}** æ¨¡å‹ï¼ç°åœ¨å¯ä»¥è¿›è¡Œé¢„æµ‹ã€‚")
            
            # --- é¢„æµ‹ç•Œé¢ ---
            st.subheader("æ­¥éª¤ 2: è¾“å…¥å‚æ•°è¿›è¡Œé¢„æµ‹")
            st.warning("è¯·ç¡®ä¿è¾“å…¥çš„å‚æ•°ä¸åŠ è½½çš„æ¨¡å‹ç±»å‹ç›¸åŒ¹é…ã€‚")
            
            form = st.form(key='prediction_form')
            with form:
                col1, col2, col3 = st.columns(3)
                with col1:
                    temp = st.number_input("è€åŒ–æ¸©åº¦ (Â°C)", min_value=0.0, max_value=200.0, value=85.0, step=0.5)
                with col2:
                    humidity = st.number_input("è€åŒ–æ¹¿åº¦ (%)", min_value=0.0, max_value=100.0, value=75.0, step=0.5)
                with col3:
                    time = st.number_input("è€åŒ–æ—¶é—´ (å°æ—¶)", min_value=0.0, max_value=1000.0, value=24.0, step=1.0)
                
                weld_status = st.selectbox("æœ‰æ— ç†”æ¥ç—•", options=[0, 1], format_func=lambda x: "æ— ç†”æ¥ç—•" if x == 0 else "æœ‰ç†”æ¥ç—•")
                
                submit_button = st.form_submit_button(label="ğŸ”® è¿è¡Œé¢„æµ‹")

            if submit_button:
                # å‡†å¤‡è¾“å…¥æ•°æ®
                raw_input_data = pd.DataFrame([[temp, humidity, time]], columns=['è€åŒ–æ¸©åº¦', 'è€åŒ–æ¹¿åº¦', 'è€åŒ–æ—¶é—´'])
                
                # ä½¿ç”¨åŠ è½½çš„scalerè¿›è¡Œå½’ä¸€åŒ–
                normalized_input = scaler.transform(raw_input_data)
                
                # ç»„åˆæ‰€æœ‰ç‰¹å¾
                final_input = pd.DataFrame(normalized_input, columns=['è€åŒ–æ¸©åº¦_normalized', 'è€åŒ–æ¹¿åº¦_normalized', 'è€åŒ–æ—¶é—´_normalized'])
                final_input['æœ‰æ— ç†”æ¥ç—•(0/1)'] = weld_status
                
                # ç¡®ä¿åˆ—é¡ºåºä¸è®­ç»ƒæ—¶ä¸€è‡´
                final_input = final_input[features]

                # è¿›è¡Œé¢„æµ‹
                prediction = model.predict(final_input)
                
                st.success(f"é¢„æµ‹çš„ **{loaded_model_type}** ç»“æœä¸º:")
                st.metric(label=loaded_model_type, value=f"{prediction[0]:.2f}")

        except Exception as e:
            st.error(f"åŠ è½½æ¨¡å‹æˆ–é¢„æµ‹æ—¶å‘ç”Ÿé”™è¯¯: {e}. è¯·ç¡®ä¿ä¸Šä¼ äº†æ­£ç¡®çš„æ¨¡å‹æ–‡ä»¶ã€‚")